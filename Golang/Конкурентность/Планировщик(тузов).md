### Конкурентное vs параллельное выполнение

**Конкурентность** - грубо говоря быстрое переключение между задачами. Допустим у нас одно ядро процессора. Он переключается очень быстро между задачами чтобы обеспечивать нам многозадачность.
Когда у нас одновременно в работе несколько задач, но в каждый момент времени мы не обязательно выполняем их все одновременно. Возможно, мы вообще можем одновременно работать лишь над одной задачей, переключаясь между ними в определенные моменты времени. Если говорить более строго, это когда две или более задачи могут начинаться, выполняться и завершаться в перекрывающиеся временные промежутки, но не обязательно одновременно.


**Параллельность** - задачи одновременно выполняются. Допустим на 4-ёх ядрах процессора. 4 задачи выполняются одновременно

**Эти термины не взаимоисключающие, конкурентный код может выполняться параллельно.**

> “Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.” — Rob Pike

Конкурентное выполнение наглядно:

![[Pasted image 20260201134625.png | 450]]

сначала выполняет все строки кода первой функции

![[Pasted image 20260201134659.png | 300]]

потом все строчки второй или вообще в разнобой

Параллельное выполнение наглядно:

![[Pasted image 20260201134727.png | 450]]

### Планировщик ОС

**Эта сущность управляет потоками.** 

грубо говоря, допустим у нас один процессор, именно планировщик решает. Какая задача подождёт, какая задача должна выполниться непременно. Он управляет тредами(последовательность команд, которая выполняется в рамках одного процесса)

Треды могут находиться в трёх состояниях:

![[Pasted image 20260201135202.png | 450]]

Планировщик ОС может переключаться треды. То есть менять состояние тредов(с waiting на runnable и т.д.) то есть менять **контекст** и эта операция довольно недешёвая. Это переключение случайное. Мы не можем на него влиять. Это поведение является **вытесняющей многозадачностью(preemtive multitasking)**. 

Наглядная проблема переключения контекстов:

![[Pasted image 20260201141052.png | 400]]

А вот когда будет задач больше:

![[Pasted image 20260201141110.png | 400]]

![[Pasted image 20260201141130.png | 400]]

### Планировщик в GO
**ОС ничего не знает о планировщике, это абстракция на уровне приложения**
разница с планировщиком ОС лишь в том что все наши потоки(горутины) живут в user space'е

![[Pasted image 20260201143725.png | 400]]

**Состояния горутин:**
- running
- runnable
- waiting

![[Pasted image 20260201143924.png | 500]]

Одно и тоже с разницей в том, что горутина выполняется в потоке, а не на процессоре

##### Модель планировщика 1:1(количество горутин = количество потоков)

Мы передаём горутину процессору, он создаёт поток для этой горутины и связывает их

![[Pasted image 20260201144219.png | 200]]

Когда горутины перестаёт работать то тред тоже исчезает

Чтобы у нас не плодилось куча потоков мы используем thread pool. То есть концепция, когда наши потоки не исчезают, а остаются в пуле и ждут, чтобы пришла горутина. Так как потоки очень много стоят, то у нас их может быть лишь ограниченное количество, к примеру их у нас 8.  Если все 8 заняты, то горутина ожидает пока не выполнится другая горутина, чтобы выполниться на освободившемся потоке. Это концепция ждущих горутин - **Global Run Queue - GRQ**. 

![[Pasted image 20260201145007.png | 500]]

FIFO / LIFO - концепции очереди. 

Количество тредов = количеству ядер процессора:

![[Pasted image 20260201145543.png | 500]]

Есть проблема касательно того что у нас работают несколько процессоров и они забирают горутины из GRQ, таким образом они могут взять одну и ту же горутины и это приведёт к плохим последствиям. Для того чтобы синхронизировать доступ к общему ресурсу, нужен мьютекс. Это самое просто решение(суть в том что когда кто-то получает доступ к ресурсу, он временно его блокирует чтобы никто другой не смог работать с ним). 

В момент когда процессор обращается к глобальной очереди она блокируется. Поэтому другой процессор не может достать оттуда горутину. Процессор забирает себе одну из горутин и происходит разблокировка.

![[Pasted image 20260201150734.png | 550]]

##### Модель M x N(на M тредах выполняется N горутин)

Чтобы на замедлялась программа на большом количестве ядер процессора у нас появляется **LRQ - local run queue**. В первую очередь процессор полезет в локальную очередь, а потом уже в глобальную. Чтобы не произшло такой ситуации, что горутины простаивают без дела в глобальной очереди(например у нас в локальной очереди очень много горутин) процессор заглядывает в глобальную очередь раз в 60 выполнений - 1/61: GRQ

![[Pasted image 20260201151305.png | 500]]

##### work-stealing - когда один из потоков простаивает. А у другого к примеру на выполнение стоит 4 горутины, свободный процессор украдёт половину от общего горутин у занятого процессора. Очевидно это нужно, чтобы балансировать работу процессоров.

#### Алгоритм поиска работы процессором:
- 1/61 GRQ
- LRQ
- Локальная очередь другого процессора(work-stealing).
- GRQ

syscall - в кратце. Мы звоним куда-то и пока место звонка подбирает информацию чтобы передать нам. Мы по сути нихуя не делаем. Ну или:\
**SYSCALL** - звонок в ядро и это context switching и поток переходит в статус waiting а это означает что он не может выполнять горутины(переключаться не может) и горутины в очереди начинают голодать 

Альтернативный ответ - вызов ядра, который может блокировать поток (например чтение файла, блокирующее read )

Когда происходит syscall, наш поток блокируется. Горутины начинают голодать. Из этого следует **Hand-off**

**Hand-off** - это механизм, он работает тогда когда поток теряет связь с процессором из-за системного вызова, перед системным вызовом создаётся новый поток и он связывается с этим процессом. Если в очереди процессора нет горутин, нового потока не будет.

![[Pasted image 20260201160720.png | 500]]

![[Pasted image 20260201160736.png | 500]]

Надо стараться совершать как можно меньше syscall'ов иначе у нас будет просто миллион тредов. Если syscall короткий, то мы можем не создавать новый тред, а дождаться ответа.

**Sysmon** - специальный поток в GO(M), он не привязан к конкретному процессору, работает в фоном режиме и следит за порядком в системе. Именно он высчитывает 10мс syscall'у и если syscall превышает это время, то он делает hand-off.
![[Pasted image 20260201162120.png | 550]]

Что происходит с горутиной, после того как она застрявает ожидая выполнения системного вызова? Она либо уходит в свободный процессор откуда мы её забрали, либо если она занята, она уходит в **GRQ**. Это является **M(тредов):P(процессоров):N(горутин) model**

Чтобы у нас не блокировался поток с горутиной ожидающей syscall, у нас есть такой инструмент как `epoll` именно он занимается системным вызовом. Периодически мы заглядываем туда чтобы получить ответ. При работе с файлами syscall по-любому породит новый тред, с сетевыми запросами это не работает так это будет асинхронный syscall. 

![[Pasted image 20260201162830.png | 500]]